{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2651,"status":"ok","timestamp":1649914029886,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"Aa3vssxUeCH7","outputId":"1d7be39b-3267-48c7-c092-ae6d5cbdaf63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: av in /usr/local/lib/python3.7/dist-packages (9.1.1)\n"]}],"source":["!pip install av"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2796,"status":"ok","timestamp":1649914032679,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"Syerlmu_w_tj","outputId":"8c34323d-d2f1-4139-e913-e6ed3a42c0d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"irrmWY6cYBjy"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import datasets, models, transforms\n","from torchvision.transforms import ToTensor\n","from torch import nn\n","from torch import optim\n","import os\n","import numpy as np\n","import pandas as pd\n","from torchvision.io import read_video\n","import matplotlib.pyplot as plt\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYPWl-M4Gkzf"},"outputs":[],"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-L8-yGbSmMHx"},"outputs":[],"source":["import torch.nn.functional as F\n","from torchsummary import summary\n","from torch import optim\n","\n","# dataset and transformation\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import os\n","\n","# display images\n","from torchvision import utils\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# utils\n","import time\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQev2ZBJfMoT"},"outputs":[],"source":["# define transformation\n","#transformation = transforms.Compose([\n","#                    transforms.ToTensor(),\n","#                    transforms.Resize(64)\n","#])\n","#이 방법쓰면 바로\n","preprocess_new_ver = transforms.Compose(\n","    [transforms.ToPILImage(),\n","    transforms.Resize((244,244)),\n","    #transforms.Resize((128,128)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6B3b2XA-X3Mt"},"outputs":[],"source":["#annotation_file : 정답 라벨링 되어 있는 csv파일\n","#video_data.csv\n","#video_dir = 이미지 들어간 폴더.\n","#out_folder/mixed\n","class MyOwnDataset(Dataset):\n","    def __init__(self, annotations_file, video_dir, transform=None, target_transform=None):\n","        self.video_labels=pd.read_csv(annotations_file, names=['file_name', 'label'])\n","        self.video_dir = video_dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","    def __len__(self):\n","        return len(self.video_labels)\n","    def __getitem__(self, idx):\n","        video_path = os.path.join(self.video_dir, self.video_labels.iloc[idx,0])\n","        #video = read_video(video_path)\n","        #video = EncodedVideo.from_path(video_path)\n","        #video_data=video.get_clip(start_sec = 0, end_sec = (num_frames * sampling_rate)/frames_per_second)\n","        video,_,_ = read_video(video_path, start_pts=0, end_pts=29)#30개의 프레임 사용\n","        video = video.permute(0,3,1,2)\n","        label = self.video_labels.iloc[idx,1]\n","        if(self.transform):\n","          #video_data = self.transform(video_data)\n","          video_data_list = []\n","          for i in video:\n","            video_data_list.append(self.transform(i))\n","          video_data = torch.stack(video_data_list, dim=0)\n","        #if(self.target_transform):#라벨 부분 변경해주는거\n","        #  label = self.target_transform(label)\n","        if(label == 0):\n","          #label = torch.FloatTensor([1.0, 0.0])\n","          label=torch.Tensor([0.0]).type(torch.LongTensor)\n","        else:\n","          #label = torch.FloatTensor([0.0, 1.0])\n","          label=torch.Tensor([1.0]).type(torch.LongTensor)\n","        #sample = {'video':video, 'label': label}\n","        #return sample\n","        return video_data, label\n","    def use_pandas_before(self, pandas_dataframe):\n","        self.video_labels = pandas_dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vRrJPiPuZy4l"},"outputs":[],"source":["cur_path = os.getcwd()\n","cur_path+='/drive/Shareddrives/capstone_data_process/temp'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hwLZaEGZ11G"},"outputs":[],"source":["#데이터 읽을 떄 경로 지정해 줘야함.\n","all_data = pd.read_csv((cur_path+'/celeb-df_v2/video_data.csv'), names=['file_name', 'label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1649914034163,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"xDIzHf2HI-6G","outputId":"1bc75195-7233-430c-b64b-1694647a7ac0"},"outputs":[{"output_type":"stream","name":"stdout","text":["566 5349 5915\n"]}],"source":["real_num = len(all_data[all_data['label'] == 1])\n","fake_num = len(all_data[all_data['label'] == 0])\n","print(real_num, fake_num , real_num+fake_num)\n","#갯수로만 보면 566/5349*100 = 10.5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RfKYFAhYJkfb"},"outputs":[],"source":["real_alls = all_data[all_data['label'] == 1]\n","fake_sample = all_data[all_data['label'] == 0].sample(frac=0.11)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1649914034164,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"yHHhPu7LJv1c","outputId":"c908592a-c863-4e7e-d03c-60cac8fbc22f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["588"]},"metadata":{},"execution_count":12}],"source":["len(fake_sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1649914034164,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"XvkjczyRKcMx","outputId":"1b19f121-3db5-4946-a460-01bb587c20ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n"]}],"source":["print(type(real_alls), type(fake_sample))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1649914034165,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"M7sE1mXrJ7WT","outputId":"03c63b1f-67b4-4c15-b2bc-99b0e83c7894"},"outputs":[{"output_type":"display_data","data":{"text/plain":["               file_name  label\n","0           id0_0000.avi      1\n","1           id0_0001.avi      1\n","2           id0_0002.avi      1\n","3           id0_0003.avi      1\n","4           id0_0004.avi      1\n","...                  ...    ...\n","1317  id41_id47_0003.avi      0\n","2732   id28_id0_0006.avi      0\n","2039  id24_id21_0005.avi      0\n","2137  id21_id25_0002.avi      0\n","1616  id58_id53_0005.avi      0\n","\n","[1154 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-dd9049b0-41f7-4640-876d-868864f19ffa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id0_0000.avi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id0_0001.avi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id0_0002.avi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id0_0003.avi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id0_0004.avi</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1317</th>\n","      <td>id41_id47_0003.avi</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2732</th>\n","      <td>id28_id0_0006.avi</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2039</th>\n","      <td>id24_id21_0005.avi</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2137</th>\n","      <td>id21_id25_0002.avi</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1616</th>\n","      <td>id58_id53_0005.avi</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1154 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd9049b0-41f7-4640-876d-868864f19ffa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dd9049b0-41f7-4640-876d-868864f19ffa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dd9049b0-41f7-4640-876d-868864f19ffa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["all_data_subset = pd.concat([real_alls, fake_sample])\n","display(all_data_subset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvADHOnbaMIo"},"outputs":[],"source":["#훈련 데이터셋 data_train       0.6\n","#검증 데이터셧 data_validation  0.2\n","#테스트 데이터셋 data_test      0.2\n","########################################\n","#data_train, data_test = train_test_split(all_data, test_size = 0.2, random_state=2022)\n","#data_train, data_validation = train_test_split(data_train, test_size=0.25, random_state=2022)\n","data_train, data_test = train_test_split(all_data_subset, test_size = 0.2, random_state=2022)\n","data_train, data_validation = train_test_split(data_train, test_size=0.25, random_state=2022)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649914034165,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"ToArW0XwaPvA","outputId":"907241f5-efd8-4187-fb09-2d0ae2fd7ec8"},"outputs":[{"output_type":"stream","name":"stdout","text":["692 231 231\n"]}],"source":["print(len(data_train), len(data_validation), len(data_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9zYNf0Xa7M1"},"outputs":[],"source":["#경로는 사용할때 조정해줘야함\n","train_data = MyOwnDataset((cur_path+'/celeb-df_v2/video_data.csv'), (cur_path+'/celeb-df_v2/pre_process/mixed'), preprocess_new_ver)\n","validation_data = MyOwnDataset((cur_path+'/celeb-df_v2/video_data.csv'), (cur_path+'/celeb-df_v2/pre_process/mixed'), preprocess_new_ver)\n","test_data = MyOwnDataset((cur_path+'/celeb-df_v2/video_data.csv'), (cur_path+'/celeb-df_v2/pre_process/mixed'), preprocess_new_ver)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1649914034165,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"KO-YYE_Eb6mR","outputId":"0c4339d3-b282-4731-c3e3-55d1704c8147"},"outputs":[{"output_type":"stream","name":"stdout","text":["692 231 231\n"]}],"source":["train_data.use_pandas_before(data_train)\n","validation_data.use_pandas_before(data_validation)\n","test_data.use_pandas_before(data_test)\n","print(len(train_data), len(validation_data), len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9aBLhcxasIO"},"outputs":[],"source":["train_dataloader = DataLoader(train_data, batch_size=2, shuffle=True)\n","validation_dataloader = DataLoader(validation_data, batch_size=2, shuffle=True)\n","test_dataloader = DataLoader(test_data, batch_size=2, shuffle=True)\n","#train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True)\n","#validation_dataloader = DataLoader(validation_data, batch_size=4, shuffle=True)\n","#test_dataloader = DataLoader(test_data, batch_size=4, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vzQqxpbICTo"},"outputs":[],"source":["#is_fake = 0\n","#is_real = 0\n","#for first, second in validation_dataloader:\n","#  #print(second)\n","#  for i in second.view(-1):\n","#    if(i ==0):\n","#      is_fake +=1\n","#    else:\n","#      is_real += 1\n","#print(is_fake, is_real)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649914034166,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"R4lYegCdKXkC","outputId":"476db85b-faba-45b2-f7ef-2e98285a4a75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/Shareddrives/capstone_data_process/temp'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["cur_path"]},{"cell_type":"code","source":["class Model2(nn.Module):\n","    def __init__(self, num_classes=2,latent_dim= 1664, lstm_layers=1 , hidden_dim = 1664, bidirectional = False):\n","        super(Model2, self).__init__()\n","        #model = models.mobilenet_v2(pretrained=True)\n","        model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet169', pretrained=True)\n","        self.model = nn.Sequential(*list(model.children())[:-1])\n","        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n","        self.dp = nn.Dropout(0.5)\n","        self.linear1 = nn.Linear(hidden_dim,num_classes)\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\n","    def forward(self, x):\n","        batch_size,seq_length, c, h, w = x.shape\n","        x = x.view(batch_size * seq_length, c, h, w)\n","        fmap = self.model(x)\n","        x = self.avgpool(fmap)\n","        #print('@',x.shape)\n","        x = x.view(batch_size,seq_length,-1)\n","        #print('@@',x.shape)\n","        x_lstm,_ = self.lstm(x,None)\n","        sp_frame_index = torch.argmax(torch.mean(x,dim=(0,2)))\n","        #print('@@@',x.shape)\n","        return sp_frame_index, fmap,self.dp(self.linear1(torch.mean(x_lstm,dim = 1)))"],"metadata":{"id":"dcqEPwU0lVFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda'\n","model = Model2().to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jx-GnULel6WP","executionInfo":{"status":"ok","timestamp":1649914039622,"user_tz":-540,"elapsed":5466,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"}},"outputId":"205d7455-f800-44e5-c72a-3e969974c160"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lcqKc7SPY5A8"},"outputs":[],"source":["device = 'cuda'\n","model = model.to(device)\n","#model.load_state_dict(torch.load(cur_path+'/trained_models/sgd_model_version5_lr_1e-07_val_0.262584_acc_74.03_f1_0.73_state_dict_sig.pt'))\n","loss_history = {'train': [], 'val': []}\n","metric_history = {'train': [], 'val': []}\n","best_loss = float('inf')\n","best_model_wts = copy.deepcopy(model.state_dict())\n","#start_time = time.time()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQa9MKhFAHIe"},"outputs":[],"source":["#여기서부터 학습 한번 진행시켜보자....\n","loss_function = nn.CrossEntropyLoss().cuda()#이것도 .cuda()붙여줘야하나\n","#loss_function = nn.BCELoss().cuda()\n","opt = optim.Adam(model.parameters(), lr=0.0001)\n","#opt = optim.SGD(model.parameters(), lr=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yo_JjmD_APNP"},"outputs":[],"source":["lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5, min_lr =0.0000001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649914039623,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"KKnYiNpyIxPx","outputId":"e394ab36-63d3-4e7d-9d02-0c43f67ba499"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/capstone_data_process/temp\n","/content/drive/Shareddrives/capstone_data_process/temp/trained_models\n"]}],"source":["epoch = 100\n","print(cur_path)\n","trained_model_path = cur_path+'/trained_models'\n","print(trained_model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zg3AoYFQKu4m"},"outputs":[],"source":["def get_lr(opt):\n","    for param_group in opt.param_groups:\n","        return param_group['lr']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVpfK5PKgt2I"},"outputs":[],"source":["#원본/예측\n","deepfake_deepfake = 0\n","deepfake_normal = 0\n","normal_deepfake = 0\n","normal_normal = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649914039624,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"},"user_tz":-540},"id":"GTRflkyiwawO","outputId":"e454d766-a9b3-47a9-ea66-acf096f1d790"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["231"]},"metadata":{},"execution_count":30}],"source":["len(validation_dataloader.dataset)"]},{"cell_type":"markdown","metadata":{"id":"nU41gp9gF1Ui"},"source":["function ClickConnect(){\n","    document.querySelector(\"colab-toolbar-button#connect\").click() \n","}\n","setInterval(ClickConnect, 60 * 1000)"]},{"cell_type":"code","source":["#best_loss = 0.262584"],"metadata":{"id":"QtSHuMgAhvw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bAyNSDGE-zv"},"outputs":[],"source":["import shutil"]},{"cell_type":"code","source":["#print_confusion_matrix(torch.argmax(torch.argmax(pred, dim = 1)), b.view(-1))\n","#confusion_matrix(b.view(-1).numpy(), torch.argmax(pred, dim = 1).cpu().numpy())"],"metadata":{"id":"tNW-gnFwT2Pp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sn\n","#Output confusion matrix\n","def print_confusion_matrix(y_true, y_pred):\n","    cm = confusion_matrix(y_true, y_pred)\n","    print(cm[0][0], cm[0][1],cm[1][0],cm[1][1])\n","    calculated_acc = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+ cm[1][1])\n","    f1_report = metrics.classification_report(y_true,y_pred)\n","    print(\"Calculated Accuracy\",calculated_acc*100,\"f1-score\",f1_report)"],"metadata":{"id":"e46yvnJVpRy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7XgSlU_Kkvr","outputId":"4db322dc-65b6-49aa-a8ed-ba99f3e37ed9","executionInfo":{"status":"ok","timestamp":1649958335375,"user_tz":-540,"elapsed":44295756,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/99, current lr= 0.0001\n","75 42 36 78\n","Calculated Accuracy 66.23376623376623 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.68      0.64      0.66       117\n","         1.0       0.65      0.68      0.67       114\n","\n","    accuracy                           0.66       231\n","   macro avg       0.66      0.66      0.66       231\n","weighted avg       0.66      0.66      0.66       231\n","\n","Update Model with best Validation Result\n","train loss: 0.359494, val loss: 0.319259, time: 16.9185 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 1/99, current lr= 0.0001\n","95 22 66 48\n","Calculated Accuracy 61.904761904761905 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.59      0.81      0.68       117\n","         1.0       0.69      0.42      0.52       114\n","\n","    accuracy                           0.62       231\n","   macro avg       0.64      0.62      0.60       231\n","weighted avg       0.64      0.62      0.60       231\n","\n","train loss: 0.335950, val loss: 0.326391, time: 24.0953 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 2/99, current lr= 0.0001\n","72 45 25 89\n","Calculated Accuracy 69.6969696969697 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.74      0.62      0.67       117\n","         1.0       0.66      0.78      0.72       114\n","\n","    accuracy                           0.70       231\n","   macro avg       0.70      0.70      0.70       231\n","weighted avg       0.70      0.70      0.70       231\n","\n","Update Model with best Validation Result\n","train loss: 0.340271, val loss: 0.302456, time: 31.3336 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 3/99, current lr= 0.0001\n","42 75 15 99\n","Calculated Accuracy 61.038961038961034 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.74      0.36      0.48       117\n","         1.0       0.57      0.87      0.69       114\n","\n","    accuracy                           0.61       231\n","   macro avg       0.65      0.61      0.59       231\n","weighted avg       0.65      0.61      0.58       231\n","\n","train loss: 0.329562, val loss: 0.321451, time: 38.5351 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 4/99, current lr= 0.0001\n","105 12 44 70\n","Calculated Accuracy 75.75757575757575 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.70      0.90      0.79       117\n","         1.0       0.85      0.61      0.71       114\n","\n","    accuracy                           0.76       231\n","   macro avg       0.78      0.76      0.75       231\n","weighted avg       0.78      0.76      0.75       231\n","\n","Update Model with best Validation Result\n","train loss: 0.317544, val loss: 0.279820, time: 45.7650 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 5/99, current lr= 0.0001\n","96 21 46 68\n","Calculated Accuracy 70.995670995671 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.68      0.82      0.74       117\n","         1.0       0.76      0.60      0.67       114\n","\n","    accuracy                           0.71       231\n","   macro avg       0.72      0.71      0.71       231\n","weighted avg       0.72      0.71      0.71       231\n","\n","train loss: 0.319560, val loss: 0.282400, time: 52.9657 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 6/99, current lr= 0.0001\n","75 42 14 100\n","Calculated Accuracy 75.75757575757575 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.64      0.73       117\n","         1.0       0.70      0.88      0.78       114\n","\n","    accuracy                           0.76       231\n","   macro avg       0.77      0.76      0.75       231\n","weighted avg       0.77      0.76      0.75       231\n","\n","Update Model with best Validation Result\n","train loss: 0.299408, val loss: 0.248896, time: 60.1877 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 7/99, current lr= 0.0001\n","116 1 80 34\n","Calculated Accuracy 64.93506493506493 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.59      0.99      0.74       117\n","         1.0       0.97      0.30      0.46       114\n","\n","    accuracy                           0.65       231\n","   macro avg       0.78      0.64      0.60       231\n","weighted avg       0.78      0.65      0.60       231\n","\n","train loss: 0.300125, val loss: 0.302035, time: 67.3987 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 8/99, current lr= 0.0001\n","73 44 19 95\n","Calculated Accuracy 72.72727272727273 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.79      0.62      0.70       117\n","         1.0       0.68      0.83      0.75       114\n","\n","    accuracy                           0.73       231\n","   macro avg       0.74      0.73      0.72       231\n","weighted avg       0.74      0.73      0.72       231\n","\n","train loss: 0.300010, val loss: 0.283450, time: 74.6045 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 9/99, current lr= 0.0001\n","115 2 70 44\n","Calculated Accuracy 68.83116883116884 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.62      0.98      0.76       117\n","         1.0       0.96      0.39      0.55       114\n","\n","    accuracy                           0.69       231\n","   macro avg       0.79      0.68      0.66       231\n","weighted avg       0.79      0.69      0.66       231\n","\n","train loss: 0.301860, val loss: 0.289157, time: 81.8074 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 10/99, current lr= 0.0001\n","105 12 31 83\n","Calculated Accuracy 81.38528138528139 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.77      0.90      0.83       117\n","         1.0       0.87      0.73      0.79       114\n","\n","    accuracy                           0.81       231\n","   macro avg       0.82      0.81      0.81       231\n","weighted avg       0.82      0.81      0.81       231\n","\n","Update Model with best Validation Result\n","train loss: 0.286385, val loss: 0.236423, time: 89.0244 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 11/99, current lr= 0.0001\n","23 94 0 114\n","Calculated Accuracy 59.307359307359306 f1-score               precision    recall  f1-score   support\n","\n","         0.0       1.00      0.20      0.33       117\n","         1.0       0.55      1.00      0.71       114\n","\n","    accuracy                           0.59       231\n","   macro avg       0.77      0.60      0.52       231\n","weighted avg       0.78      0.59      0.52       231\n","\n","train loss: 0.295323, val loss: 0.707487, time: 96.2175 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 12/99, current lr= 0.0001\n","56 61 6 108\n","Calculated Accuracy 70.995670995671 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.90      0.48      0.63       117\n","         1.0       0.64      0.95      0.76       114\n","\n","    accuracy                           0.71       231\n","   macro avg       0.77      0.71      0.69       231\n","weighted avg       0.77      0.71      0.69       231\n","\n","train loss: 0.272400, val loss: 0.280065, time: 103.4196 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 13/99, current lr= 0.0001\n","68 49 23 91\n","Calculated Accuracy 68.83116883116884 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.75      0.58      0.65       117\n","         1.0       0.65      0.80      0.72       114\n","\n","    accuracy                           0.69       231\n","   macro avg       0.70      0.69      0.69       231\n","weighted avg       0.70      0.69      0.68       231\n","\n","train loss: 0.276288, val loss: 0.325203, time: 110.6298 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 14/99, current lr= 0.0001\n","99 18 21 93\n","Calculated Accuracy 83.11688311688312 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.82      0.85      0.84       117\n","         1.0       0.84      0.82      0.83       114\n","\n","    accuracy                           0.83       231\n","   macro avg       0.83      0.83      0.83       231\n","weighted avg       0.83      0.83      0.83       231\n","\n","Update Model with best Validation Result\n","train loss: 0.254320, val loss: 0.168713, time: 117.8715 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 15/99, current lr= 0.0001\n","92 25 8 106\n","Calculated Accuracy 85.71428571428571 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.92      0.79      0.85       117\n","         1.0       0.81      0.93      0.87       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.86      0.86      0.86       231\n","weighted avg       0.87      0.86      0.86       231\n","\n","train loss: 0.250423, val loss: 0.204249, time: 125.0722 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 16/99, current lr= 0.0001\n","61 56 0 114\n","Calculated Accuracy 75.75757575757575 f1-score               precision    recall  f1-score   support\n","\n","         0.0       1.00      0.52      0.69       117\n","         1.0       0.67      1.00      0.80       114\n","\n","    accuracy                           0.76       231\n","   macro avg       0.84      0.76      0.74       231\n","weighted avg       0.84      0.76      0.74       231\n","\n","train loss: 0.218773, val loss: 0.285998, time: 132.2723 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 17/99, current lr= 0.0001\n","107 10 21 93\n","Calculated Accuracy 86.58008658008657 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.91      0.87       117\n","         1.0       0.90      0.82      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.236691, val loss: 0.190904, time: 139.4750 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 18/99, current lr= 0.0001\n","99 18 13 101\n","Calculated Accuracy 86.58008658008657 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.88      0.85      0.86       117\n","         1.0       0.85      0.89      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.214308, val loss: 0.179667, time: 146.6699 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 19/99, current lr= 0.0001\n","99 18 12 102\n","Calculated Accuracy 87.01298701298701 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.89      0.85      0.87       117\n","         1.0       0.85      0.89      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.197373, val loss: 0.180912, time: 153.8984 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 20/99, current lr= 0.0001\n","110 7 32 82\n","Calculated Accuracy 83.11688311688312 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.77      0.94      0.85       117\n","         1.0       0.92      0.72      0.81       114\n","\n","    accuracy                           0.83       231\n","   macro avg       0.85      0.83      0.83       231\n","weighted avg       0.85      0.83      0.83       231\n","\n","Update Model with best Validation Result\n","train loss: 0.172167, val loss: 0.155027, time: 161.1135 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 21/99, current lr= 0.0001\n","105 12 66 48\n","Calculated Accuracy 66.23376623376623 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.61      0.90      0.73       117\n","         1.0       0.80      0.42      0.55       114\n","\n","    accuracy                           0.66       231\n","   macro avg       0.71      0.66      0.64       231\n","weighted avg       0.71      0.66      0.64       231\n","\n","train loss: 0.177602, val loss: 0.309179, time: 168.3188 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 22/99, current lr= 0.0001\n","97 20 8 106\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.92      0.83      0.87       117\n","         1.0       0.84      0.93      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.207146, val loss: 0.159748, time: 175.5242 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 23/99, current lr= 0.0001\n","109 8 38 76\n","Calculated Accuracy 80.08658008658008 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.74      0.93      0.83       117\n","         1.0       0.90      0.67      0.77       114\n","\n","    accuracy                           0.80       231\n","   macro avg       0.82      0.80      0.80       231\n","weighted avg       0.82      0.80      0.80       231\n","\n","train loss: 0.163095, val loss: 0.238938, time: 182.7259 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 24/99, current lr= 0.0001\n","109 8 25 89\n","Calculated Accuracy 85.71428571428571 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.81      0.93      0.87       117\n","         1.0       0.92      0.78      0.84       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.87      0.86      0.86       231\n","weighted avg       0.86      0.86      0.86       231\n","\n","train loss: 0.175945, val loss: 0.168137, time: 189.9430 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 25/99, current lr= 0.0001\n","108 9 40 74\n","Calculated Accuracy 78.78787878787878 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.73      0.92      0.82       117\n","         1.0       0.89      0.65      0.75       114\n","\n","    accuracy                           0.79       231\n","   macro avg       0.81      0.79      0.78       231\n","weighted avg       0.81      0.79      0.78       231\n","\n","train loss: 0.157648, val loss: 0.216277, time: 197.1576 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 26/99, current lr= 0.0001\n","107 10 15 99\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.88      0.91      0.90       117\n","         1.0       0.91      0.87      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","Update Model with best Validation Result\n","train loss: 0.145382, val loss: 0.154613, time: 204.3859 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 27/99, current lr= 0.0001\n","110 7 22 92\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.83      0.94      0.88       117\n","         1.0       0.93      0.81      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.158604, val loss: 0.169021, time: 211.5909 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 28/99, current lr= 0.0001\n","100 17 23 91\n","Calculated Accuracy 82.68398268398268 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.81      0.85      0.83       117\n","         1.0       0.84      0.80      0.82       114\n","\n","    accuracy                           0.83       231\n","   macro avg       0.83      0.83      0.83       231\n","weighted avg       0.83      0.83      0.83       231\n","\n","train loss: 0.162817, val loss: 0.162392, time: 218.7997 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 29/99, current lr= 0.0001\n","108 9 21 93\n","Calculated Accuracy 87.01298701298701 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.92      0.88       117\n","         1.0       0.91      0.82      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","Update Model with best Validation Result\n","train loss: 0.124929, val loss: 0.151741, time: 226.0234 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 30/99, current lr= 0.0001\n","105 12 12 102\n","Calculated Accuracy 89.6103896103896 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.90      0.90      0.90       117\n","         1.0       0.89      0.89      0.89       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","Update Model with best Validation Result\n","train loss: 0.132862, val loss: 0.143147, time: 233.2513 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 31/99, current lr= 0.0001\n","96 21 12 102\n","Calculated Accuracy 85.71428571428571 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.89      0.82      0.85       117\n","         1.0       0.83      0.89      0.86       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.86      0.86      0.86       231\n","weighted avg       0.86      0.86      0.86       231\n","\n","train loss: 0.148725, val loss: 0.185292, time: 240.4537 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 32/99, current lr= 0.0001\n","98 19 16 98\n","Calculated Accuracy 84.84848484848484 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.84      0.85       117\n","         1.0       0.84      0.86      0.85       114\n","\n","    accuracy                           0.85       231\n","   macro avg       0.85      0.85      0.85       231\n","weighted avg       0.85      0.85      0.85       231\n","\n","train loss: 0.170540, val loss: 0.180008, time: 247.6723 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 33/99, current lr= 0.0001\n","111 6 30 84\n","Calculated Accuracy 84.4155844155844 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.79      0.95      0.86       117\n","         1.0       0.93      0.74      0.82       114\n","\n","    accuracy                           0.84       231\n","   macro avg       0.86      0.84      0.84       231\n","weighted avg       0.86      0.84      0.84       231\n","\n","train loss: 0.116660, val loss: 0.180536, time: 254.9016 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 34/99, current lr= 0.0001\n","110 7 30 84\n","Calculated Accuracy 83.98268398268398 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.79      0.94      0.86       117\n","         1.0       0.92      0.74      0.82       114\n","\n","    accuracy                           0.84       231\n","   macro avg       0.85      0.84      0.84       231\n","weighted avg       0.85      0.84      0.84       231\n","\n","train loss: 0.132924, val loss: 0.165663, time: 262.1180 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 35/99, current lr= 0.0001\n","106 11 13 101\n","Calculated Accuracy 89.6103896103896 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.89      0.91      0.90       117\n","         1.0       0.90      0.89      0.89       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.148862, val loss: 0.144201, time: 269.3327 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 36/99, current lr= 0.0001\n","89 28 7 107\n","Calculated Accuracy 84.84848484848484 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.93      0.76      0.84       117\n","         1.0       0.79      0.94      0.86       114\n","\n","    accuracy                           0.85       231\n","   macro avg       0.86      0.85      0.85       231\n","weighted avg       0.86      0.85      0.85       231\n","\n","Loading best model weights!\n","train loss: 0.155863, val loss: 0.196833, time: 276.5551 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 37/99, current lr= 1e-05\n","108 9 18 96\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.92      0.89       117\n","         1.0       0.91      0.84      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","Update Model with best Validation Result\n","train loss: 0.109189, val loss: 0.141940, time: 283.7888 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 38/99, current lr= 1e-05\n","111 6 17 97\n","Calculated Accuracy 90.04329004329004 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.95      0.91       117\n","         1.0       0.94      0.85      0.89       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.111415, val loss: 0.150560, time: 291.0037 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 39/99, current lr= 1e-05\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.099473, val loss: 0.143339, time: 298.2289 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 40/99, current lr= 1e-05\n","110 7 18 96\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.94      0.90       117\n","         1.0       0.93      0.84      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.90      0.89      0.89       231\n","weighted avg       0.90      0.89      0.89       231\n","\n","train loss: 0.096133, val loss: 0.150193, time: 305.4475 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 41/99, current lr= 1e-05\n","108 9 14 100\n","Calculated Accuracy 90.04329004329004 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.89      0.92      0.90       117\n","         1.0       0.92      0.88      0.90       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.102319, val loss: 0.143862, time: 312.6654 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 42/99, current lr= 1e-05\n","107 10 10 104\n","Calculated Accuracy 91.34199134199135 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.91      0.91      0.91       117\n","         1.0       0.91      0.91      0.91       114\n","\n","    accuracy                           0.91       231\n","   macro avg       0.91      0.91      0.91       231\n","weighted avg       0.91      0.91      0.91       231\n","\n","train loss: 0.083698, val loss: 0.145535, time: 319.8864 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 43/99, current lr= 1e-05\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","Loading best model weights!\n","train loss: 0.108747, val loss: 0.157646, time: 327.1011 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 44/99, current lr= 1.0000000000000002e-06\n","108 9 20 94\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.92      0.88       117\n","         1.0       0.91      0.82      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.098012, val loss: 0.156911, time: 334.3149 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 45/99, current lr= 1.0000000000000002e-06\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.103948, val loss: 0.143800, time: 341.5401 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 46/99, current lr= 1.0000000000000002e-06\n","108 9 16 98\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.92      0.90       117\n","         1.0       0.92      0.86      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","Update Model with best Validation Result\n","train loss: 0.098528, val loss: 0.133674, time: 348.7947 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 47/99, current lr= 1.0000000000000002e-06\n","107 10 19 95\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.91      0.88       117\n","         1.0       0.90      0.83      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.104491, val loss: 0.145742, time: 356.1473 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 48/99, current lr= 1.0000000000000002e-06\n","104 13 13 101\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       117\n","         1.0       0.89      0.89      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.102922, val loss: 0.163908, time: 363.5061 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 49/99, current lr= 1.0000000000000002e-06\n","107 10 19 95\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.91      0.88       117\n","         1.0       0.90      0.83      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.102369, val loss: 0.160360, time: 370.8709 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 50/99, current lr= 1.0000000000000002e-06\n","110 7 24 90\n","Calculated Accuracy 86.58008658008657 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.82      0.94      0.88       117\n","         1.0       0.93      0.79      0.85       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.86      0.86       231\n","weighted avg       0.87      0.87      0.86       231\n","\n","train loss: 0.101926, val loss: 0.161381, time: 378.2291 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 51/99, current lr= 1.0000000000000002e-06\n","106 11 12 102\n","Calculated Accuracy 90.04329004329004 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.90      0.91      0.90       117\n","         1.0       0.90      0.89      0.90       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.093470, val loss: 0.143253, time: 385.5924 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 52/99, current lr= 1.0000000000000002e-06\n","108 9 18 96\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.92      0.89       117\n","         1.0       0.91      0.84      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","Loading best model weights!\n","train loss: 0.102080, val loss: 0.147777, time: 392.9614 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 53/99, current lr= 1.0000000000000002e-07\n","109 8 21 93\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.93      0.88       117\n","         1.0       0.92      0.82      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.102521, val loss: 0.153413, time: 400.3199 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 54/99, current lr= 1.0000000000000002e-07\n","110 7 17 97\n","Calculated Accuracy 89.6103896103896 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.94      0.90       117\n","         1.0       0.93      0.85      0.89       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.111691, val loss: 0.134485, time: 407.6696 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 55/99, current lr= 1.0000000000000002e-07\n","108 9 22 92\n","Calculated Accuracy 86.58008658008657 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.83      0.92      0.87       117\n","         1.0       0.91      0.81      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.106172, val loss: 0.153857, time: 415.0281 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 56/99, current lr= 1.0000000000000002e-07\n","111 6 23 91\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.83      0.95      0.88       117\n","         1.0       0.94      0.80      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.101181, val loss: 0.151491, time: 422.3767 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 57/99, current lr= 1.0000000000000002e-07\n","107 10 17 97\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.91      0.89       117\n","         1.0       0.91      0.85      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.112912, val loss: 0.142017, time: 429.7161 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 58/99, current lr= 1.0000000000000002e-07\n","111 6 27 87\n","Calculated Accuracy 85.71428571428571 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.80      0.95      0.87       117\n","         1.0       0.94      0.76      0.84       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.87      0.86      0.86       231\n","weighted avg       0.87      0.86      0.86       231\n","\n","train loss: 0.097804, val loss: 0.159353, time: 437.0664 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 59/99, current lr= 1.0000000000000002e-07\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.092850, val loss: 0.134521, time: 444.4200 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 60/99, current lr= 1.0000000000000002e-07\n","107 10 17 97\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.91      0.89       117\n","         1.0       0.91      0.85      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.105261, val loss: 0.152330, time: 451.7579 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 61/99, current lr= 1.0000000000000002e-07\n","109 8 16 98\n","Calculated Accuracy 89.6103896103896 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.93      0.90       117\n","         1.0       0.92      0.86      0.89       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.105361, val loss: 0.142907, time: 459.0995 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 62/99, current lr= 1.0000000000000002e-07\n","109 8 20 94\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.93      0.89       117\n","         1.0       0.92      0.82      0.87       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.102487, val loss: 0.156037, time: 466.4484 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 63/99, current lr= 1.0000000000000002e-07\n","109 8 17 97\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.93      0.90       117\n","         1.0       0.92      0.85      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.096033, val loss: 0.152207, time: 473.7910 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 64/99, current lr= 1.0000000000000002e-07\n","108 9 17 97\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.92      0.89       117\n","         1.0       0.92      0.85      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.105747, val loss: 0.146828, time: 481.1257 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 65/99, current lr= 1.0000000000000002e-07\n","106 11 19 95\n","Calculated Accuracy 87.01298701298701 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.91      0.88       117\n","         1.0       0.90      0.83      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.110220, val loss: 0.171226, time: 488.4646 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 66/99, current lr= 1.0000000000000002e-07\n","108 9 19 95\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.92      0.89       117\n","         1.0       0.91      0.83      0.87       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.091395, val loss: 0.155263, time: 495.7981 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 67/99, current lr= 1.0000000000000002e-07\n","108 9 18 96\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.92      0.89       117\n","         1.0       0.91      0.84      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.103655, val loss: 0.153692, time: 503.1347 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 68/99, current lr= 1.0000000000000002e-07\n","107 10 17 97\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.91      0.89       117\n","         1.0       0.91      0.85      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.099409, val loss: 0.137561, time: 510.4740 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 69/99, current lr= 1.0000000000000002e-07\n","106 11 8 106\n","Calculated Accuracy 91.77489177489177 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.93      0.91      0.92       117\n","         1.0       0.91      0.93      0.92       114\n","\n","    accuracy                           0.92       231\n","   macro avg       0.92      0.92      0.92       231\n","weighted avg       0.92      0.92      0.92       231\n","\n","train loss: 0.106745, val loss: 0.141258, time: 517.8024 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 70/99, current lr= 1.0000000000000002e-07\n","111 6 20 94\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.95      0.90       117\n","         1.0       0.94      0.82      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.101100, val loss: 0.169819, time: 525.1467 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 71/99, current lr= 1.0000000000000002e-07\n","106 11 17 97\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.91      0.88       117\n","         1.0       0.90      0.85      0.87       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.109597, val loss: 0.148925, time: 532.4829 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 72/99, current lr= 1.0000000000000002e-07\n","106 11 11 103\n","Calculated Accuracy 90.47619047619048 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.91      0.91      0.91       117\n","         1.0       0.90      0.90      0.90       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.094517, val loss: 0.143340, time: 539.8195 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 73/99, current lr= 1.0000000000000002e-07\n","109 8 19 95\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.93      0.89       117\n","         1.0       0.92      0.83      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.101086, val loss: 0.149352, time: 547.1597 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 74/99, current lr= 1.0000000000000002e-07\n","107 10 17 97\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.91      0.89       117\n","         1.0       0.91      0.85      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.106442, val loss: 0.154660, time: 554.5051 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 75/99, current lr= 1.0000000000000002e-07\n","103 14 16 98\n","Calculated Accuracy 87.01298701298701 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.88      0.87       117\n","         1.0       0.88      0.86      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.102894, val loss: 0.153338, time: 561.8557 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 76/99, current lr= 1.0000000000000002e-07\n","108 9 16 98\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.92      0.90       117\n","         1.0       0.92      0.86      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.105803, val loss: 0.142365, time: 569.2050 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 77/99, current lr= 1.0000000000000002e-07\n","106 11 19 95\n","Calculated Accuracy 87.01298701298701 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.91      0.88       117\n","         1.0       0.90      0.83      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.87      0.87      0.87       231\n","weighted avg       0.87      0.87      0.87       231\n","\n","train loss: 0.117439, val loss: 0.149977, time: 576.5476 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 78/99, current lr= 1.0000000000000002e-07\n","111 6 22 92\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.83      0.95      0.89       117\n","         1.0       0.94      0.81      0.87       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.093868, val loss: 0.155016, time: 583.9067 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 79/99, current lr= 1.0000000000000002e-07\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.103196, val loss: 0.137543, time: 591.2489 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 80/99, current lr= 1.0000000000000002e-07\n","109 8 24 90\n","Calculated Accuracy 86.14718614718615 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.82      0.93      0.87       117\n","         1.0       0.92      0.79      0.85       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.87      0.86      0.86       231\n","weighted avg       0.87      0.86      0.86       231\n","\n","train loss: 0.106112, val loss: 0.146577, time: 598.5884 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 81/99, current lr= 1.0000000000000002e-07\n","111 6 17 97\n","Calculated Accuracy 90.04329004329004 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.95      0.91       117\n","         1.0       0.94      0.85      0.89       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.110878, val loss: 0.141843, time: 605.9428 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 82/99, current lr= 1.0000000000000002e-07\n","110 7 18 96\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.94      0.90       117\n","         1.0       0.93      0.84      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.90      0.89      0.89       231\n","weighted avg       0.90      0.89      0.89       231\n","\n","train loss: 0.102309, val loss: 0.151703, time: 613.3007 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 83/99, current lr= 1.0000000000000002e-07\n","111 6 22 92\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.83      0.95      0.89       117\n","         1.0       0.94      0.81      0.87       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.106479, val loss: 0.145974, time: 620.6577 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 84/99, current lr= 1.0000000000000002e-07\n","108 9 20 94\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.92      0.88       117\n","         1.0       0.91      0.82      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.097943, val loss: 0.150490, time: 628.0059 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 85/99, current lr= 1.0000000000000002e-07\n","109 8 20 94\n","Calculated Accuracy 87.87878787878788 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.84      0.93      0.89       117\n","         1.0       0.92      0.82      0.87       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.88      0.88      0.88       231\n","weighted avg       0.88      0.88      0.88       231\n","\n","train loss: 0.111739, val loss: 0.142439, time: 635.3467 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 86/99, current lr= 1.0000000000000002e-07\n","108 9 23 91\n","Calculated Accuracy 86.14718614718615 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.82      0.92      0.87       117\n","         1.0       0.91      0.80      0.85       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.87      0.86      0.86       231\n","weighted avg       0.87      0.86      0.86       231\n","\n","train loss: 0.099756, val loss: 0.168752, time: 642.7032 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 87/99, current lr= 1.0000000000000002e-07\n","108 9 18 96\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.92      0.89       117\n","         1.0       0.91      0.84      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.104496, val loss: 0.143756, time: 650.0538 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 88/99, current lr= 1.0000000000000002e-07\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.103007, val loss: 0.149081, time: 657.4083 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 89/99, current lr= 1.0000000000000002e-07\n","106 11 11 103\n","Calculated Accuracy 90.47619047619048 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.91      0.91      0.91       117\n","         1.0       0.90      0.90      0.90       114\n","\n","    accuracy                           0.90       231\n","   macro avg       0.90      0.90      0.90       231\n","weighted avg       0.90      0.90      0.90       231\n","\n","train loss: 0.103291, val loss: 0.136173, time: 664.7608 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 90/99, current lr= 1.0000000000000002e-07\n","109 8 19 95\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.93      0.89       117\n","         1.0       0.92      0.83      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.107193, val loss: 0.138202, time: 672.1108 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 91/99, current lr= 1.0000000000000002e-07\n","110 7 19 95\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.94      0.89       117\n","         1.0       0.93      0.83      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.103628, val loss: 0.158766, time: 679.4730 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 92/99, current lr= 1.0000000000000002e-07\n","105 12 17 97\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.86      0.90      0.88       117\n","         1.0       0.89      0.85      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.109368, val loss: 0.144023, time: 686.8213 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 93/99, current lr= 1.0000000000000002e-07\n","108 9 16 98\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.92      0.90       117\n","         1.0       0.92      0.86      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.092204, val loss: 0.141577, time: 694.1766 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 94/99, current lr= 1.0000000000000002e-07\n","111 6 20 94\n","Calculated Accuracy 88.74458874458875 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.95      0.90       117\n","         1.0       0.94      0.82      0.88       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.104624, val loss: 0.149388, time: 701.5236 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 95/99, current lr= 1.0000000000000002e-07\n","109 8 19 95\n","Calculated Accuracy 88.31168831168831 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.93      0.89       117\n","         1.0       0.92      0.83      0.88       114\n","\n","    accuracy                           0.88       231\n","   macro avg       0.89      0.88      0.88       231\n","weighted avg       0.89      0.88      0.88       231\n","\n","train loss: 0.100729, val loss: 0.154304, time: 708.8673 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 96/99, current lr= 1.0000000000000002e-07\n","111 6 26 88\n","Calculated Accuracy 86.14718614718615 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.81      0.95      0.87       117\n","         1.0       0.94      0.77      0.85       114\n","\n","    accuracy                           0.86       231\n","   macro avg       0.87      0.86      0.86       231\n","weighted avg       0.87      0.86      0.86       231\n","\n","train loss: 0.100665, val loss: 0.157371, time: 716.2184 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 97/99, current lr= 1.0000000000000002e-07\n","108 9 16 98\n","Calculated Accuracy 89.17748917748918 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.87      0.92      0.90       117\n","         1.0       0.92      0.86      0.89       114\n","\n","    accuracy                           0.89       231\n","   macro avg       0.89      0.89      0.89       231\n","weighted avg       0.89      0.89      0.89       231\n","\n","train loss: 0.098658, val loss: 0.141371, time: 723.5670 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 98/99, current lr= 1.0000000000000002e-07\n","106 11 18 96\n","Calculated Accuracy 87.44588744588745 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.85      0.91      0.88       117\n","         1.0       0.90      0.84      0.87       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.101429, val loss: 0.155582, time: 730.9221 min\n","----------------------------------------------------------------------------------------------------\n","Epoch 99/99, current lr= 1.0000000000000002e-07\n","111 6 24 90\n","Calculated Accuracy 87.01298701298701 f1-score               precision    recall  f1-score   support\n","\n","         0.0       0.82      0.95      0.88       117\n","         1.0       0.94      0.79      0.86       114\n","\n","    accuracy                           0.87       231\n","   macro avg       0.88      0.87      0.87       231\n","weighted avg       0.88      0.87      0.87       231\n","\n","train loss: 0.106164, val loss: 0.158144, time: 738.2660 min\n","----------------------------------------------------------------------------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":35}],"source":["start_time = time.time()\n","for index in range(epoch):\n","  total_numbers = 0\n","  deepfake_deepfake = 0\n","  deepfake_normal = 0\n","  normal_deepfake = 0\n","  normal_normal = 0\n","  current_lr = get_lr(opt)\n","  print('Epoch {}/{}, current lr= {}'.format(index, epoch-1, current_lr))\n","  #model train phase\n","  model.train()\n","  train_dataloader_length = len(train_dataloader.dataset)\n","  epoch_train_loss = 0.0\n","  for data, label in train_dataloader:\n","    data = data.to(device)\n","    label = label.to(device)\n","    _, _, pred = model(data)\n","    loss_value = loss_function(pred, label.view(-1))\n","    epoch_train_loss += loss_value.item()\n","    opt.zero_grad()\n","    loss_value.backward()\n","    opt.step()\n","  epoch_train_loss /= train_dataloader_length\n","  loss_history['train'].append(epoch_train_loss)\n","  #model evaluation with validation set phase\n","  model.eval()\n","  with torch.no_grad():\n","    validation_dataloader_length = len(validation_dataloader.dataset)\n","    epoch_validation_loss = 0.0\n","    total_preds = np.array([])\n","    total_labels = np.array([])\n","    for data, label in validation_dataloader:\n","      data = data.to(device)\n","      label = label.to(device)\n","      #pred, sp_frame = model(data)\n","      _, _,pred = model(data)\n","      total_preds = np.append(total_preds, torch.argmax(pred, dim = 1).cpu().numpy())\n","      total_labels = np.append(total_labels, label.view(-1).cpu().numpy())\n","      loss_value = loss_function(pred, label.view(-1))\n","      epoch_validation_loss += loss_value.item()\n","    print_confusion_matrix(total_labels, total_preds)\n","  epoch_validation_loss /= validation_dataloader_length\n","  loss_history['val'].append(epoch_validation_loss)\n","\n","  if(epoch_validation_loss < best_loss):\n","    best_loss = epoch_validation_loss\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    torch.save(model.state_dict(), trained_model_path+'/flatten_adam_model_state_dict_sig.pt')\n","    shutil.copy(trained_model_path+'/flatten_adam_model_state_dict_sig.pt', trained_model_path+'/flatten_adam_model_state_dict_sig_spare.pt')\n","    print('Update Model with best Validation Result')\n","\n","  lr_scheduler.step(epoch_validation_loss)\n","  if(current_lr != get_lr(opt)):\n","    print('Loading best model weights!')\n","    model.load_state_dict(best_model_wts)\n","  \n","  print('train loss: %.6f, val loss: %.6f, time: %.4f min' %(epoch_train_loss, epoch_validation_loss, (time.time()-start_time)/60))\n","  print('-'*100)\n","model.load_state_dict(best_model_wts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xeWQ2bkQPx5"},"outputs":[],"source":["torch.save(model, trained_model_path+'/flatten_new_adam_model_last_choice.pt')\n","torch.save(model.state_dict(), trained_model_path+'/flatten_adam_model_last_choice_state_dict_sig.pt')\n","torch.save({'model':model.state_dict(), 'optimizer':opt.state_dict()}, trained_model_path+'/flatten_adam_model_sig_last_choice_all.tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8EXtIbpQKZq6","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1649958337966,"user_tz":-540,"elapsed":9,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"}},"outputId":"6403c264-8b85-4959-a4a4-66360758696f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","# Train-Validation progress\n","num_epochs = 100\n","\n","# plot loss progress\n","plt.title('Train-Val Loss')\n","plt.plot(range(1, num_epochs+1), loss_history['train'], label='train')\n","plt.plot(range(1, num_epochs+1), loss_history['val'], label='val')\n","plt.ylabel('Loss')\n","plt.xlabel('Training Epochs')\n","plt.legend()\n","plt.show()\n","\n","# plot accuracy progress\n","#plt.title('Train-Val Accuracy')\n","#plt.plot(range(1, num_epochs+1), metric_hist['train'], label='train')\n","#plt.plot(range(1, num_epochs+1), metric_hist['val'], label='val')\n","#plt.ylabel('Accuracy')\n","#plt.xlabel('Training Epochs')\n","#plt.legend()\n","#plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vm1rRi1h7fPb"},"outputs":[],"source":["#print(sp_frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQ6QZZbb78tB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649958337966,"user_tz":-540,"elapsed":7,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"}},"outputId":"30837c9e-aa0b-424f-c8e0-8be1306fcb4c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.1581436772435804"]},"metadata":{},"execution_count":39}],"source":["epoch_validation_loss"]},{"cell_type":"code","source":["best_loss"],"metadata":{"id":"b4J_424zSZaA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649958337967,"user_tz":-540,"elapsed":7,"user":{"displayName":"쉿쉿쉿","userId":"02827733275935633588"}},"outputId":"7b8a3ac1-f583-4444-f740-c1dd2873fad2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.13367438706481433"]},"metadata":{},"execution_count":40}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"adam_model_version7_change_with_depth_pre_trained.ipynb","provenance":[{"file_id":"1loOL2BzByusC8IthZoXv_-QObuLAAYKo","timestamp":1649126247079},{"file_id":"1ZTs4ThRvnLr-6U3vCnXNU0mQ0KglW9UE","timestamp":1648953525487}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}